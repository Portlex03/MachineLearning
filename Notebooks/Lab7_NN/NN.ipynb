{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- № 2.1 Разработать многослойный персептрон (MLP), с помощью которого можно решать задачи регрессии и классификации.\n",
    "- № 2.2 Предусмотреть возможность использования таких функции активации, как sigmoid, tanh и relu;\n",
    "- № 2.3 Предусмотреть возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой;\n",
    "- № 2.4 Реализовать обучение MLP методом обратного распространения ошибки;\n",
    "- № 2.5 Самостоятельно найти производные функций sigmoid, tanh и relu;\n",
    "- № 2.6 Реализовать классический градиентный спуск с возможностью указания шага.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoubleLinkedList\n",
    "from multipledispatch import dispatch\n",
    "from abc import ABCMeta, abstractproperty\n",
    "\n",
    "class Node:\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractproperty\n",
    "    def pref():\n",
    "        \"\"\"Ссылка на предыдущий объект\"\"\"\n",
    "\n",
    "    @abstractproperty\n",
    "    def nref():\n",
    "        \"\"\"Ссылка на следующий объект\"\"\"\n",
    "        \n",
    "class DoubleLinkedList:\n",
    "    def __init__(self) -> None:\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "    \n",
    "    def _insert_start(self, obj: Node) -> bool:\n",
    "        if not self.head:\n",
    "            self.head = obj\n",
    "            self.tail = self.head\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @dispatch(object)\n",
    "    def insert(self, obj: Node):\n",
    "        if self._insert_start(obj):\n",
    "            return self\n",
    "\n",
    "        obj.pref = self.tail\n",
    "        self.tail.nref = obj\n",
    "        \n",
    "        self.tail = obj\n",
    "        return self\n",
    "\n",
    "    @dispatch(list)\n",
    "    def insert(self, obj: list):\n",
    "        while obj:\n",
    "            self.insert(obj[0])\n",
    "            obj.pop(0)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "\n",
    "class Func(Enum):\n",
    "    linear  = (lambda x: x, \n",
    "               lambda x: 1)\n",
    "    \n",
    "    sigmoid = (lambda x: np.nan_to_num(1 / (1 + np.exp(-x))), \n",
    "               lambda x: np.nan_to_num(np.exp(x) / (1 + np.exp(x))**2))\n",
    "    \n",
    "    relu    = (lambda x: np.maximum(0, x),\n",
    "               lambda x: (x > 0) * 1)\n",
    "    \n",
    "    tanh    = (lambda x: np.nan_to_num((np.exp(2 * x) - 1) / (np.exp(2 * x) + 1)),\n",
    "               lambda x: np.nan_to_num(4 * np.exp(2 * x) / (np.exp(2 * x) + 1)**2))\n",
    "    \n",
    "    mse     = (lambda y_true, y_pred: (y_true - y_pred)**2,\n",
    "               lambda y_true, y_pred: 2 * (y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = np.dot\n",
    "def null(x) -> bool: return x.shape[0] == 0 if type(x) is np.ndarray else not bool(x)\n",
    "\n",
    "class Layer(Node):\n",
    "    def __init__(self, n_neurons: int, actFunc: Func, lmbd: float = 0.1) -> None:\n",
    "        self.n_neurons = n_neurons\n",
    "        self.actFunc, self.actFuncDer = actFunc.value\n",
    "        self.lmbd = lmbd\n",
    "        self.W, self.B = None, None\n",
    "        self.T, self.H = None, None\n",
    "        self._pref = None\n",
    "        self._nref = None\n",
    "\n",
    "    def update_weights(self) -> None:\n",
    "        if null(self.W) and null(self.B):\n",
    "            self.W = np.random.uniform(-.5, .5, (self.n_neurons,self.nref.n_neurons))\n",
    "            self.B = np.random.uniform(-.5, .5, (1, self.nref.n_neurons))\n",
    "            \n",
    "            self.dE_dW = np.zeros(self.W.shape)\n",
    "            self.dE_dB = np.zeros(self.B.shape)\n",
    "        else:\n",
    "            self.W = self.W + self.lmbd * self.dE_dW\n",
    "            self.B = self.B + self.lmbd * self.dE_dB\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        # если мы в последнем слое, то применяем функцию активации\n",
    "        if not self.nref:\n",
    "            return self.actFunc(X)\n",
    "\n",
    "        # обновление весов\n",
    "        self.update_weights()\n",
    "\n",
    "        # если это первый слой, инициализируем h\n",
    "        self.H = X if not self.pref else self.H\n",
    "\n",
    "        # считаем сумму T и применяем функцию активации для\n",
    "        # нахождения H для следующего слоя\n",
    "        self.nref.T = mul(self.H, self.W) + self.B\n",
    "        self.nref.H = self.actFunc(self.nref.T)\n",
    "        # возвращаем вектор для следующего слоя\n",
    "        return self.nref.H\n",
    "\n",
    "    def backprop(self, dE_dH):\n",
    "        # если это последний слой, принимаем производную ошибки\n",
    "        # иначе считаем как dE_dT_(i + 1) * W_T\n",
    "        self.dE_dH = dE_dH if not self.nref else mul(self.nref.dE_dT, self.W.T)\n",
    "        self.dE_dT = self.dE_dH * self.actFuncDer(self.T)\n",
    "        \n",
    "        # градиент весов предыдущего слоя\n",
    "        self.pref.dE_dW = mul(self.pref.H.T, self.dE_dT)\n",
    "        \n",
    "        # градиент смещения предыдущего слоя\n",
    "        self.pref.dE_dB = self.dE_dT\n",
    "\n",
    "    @property\n",
    "    def pref(self): return self._pref\n",
    "\n",
    "    @pref.setter\n",
    "    def pref(self, obj): self._pref = obj\n",
    "    \n",
    "    @property\n",
    "    def nref(self): return self._nref\n",
    "\n",
    "    @nref.setter\n",
    "    def nref(self, obj): self._nref = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\tdef __init__(self, layers: list[Layer], lossFunc: Func) -> None:\n",
    "\t\t# двусвязный список s1 <--> s2 <--> s3 <--> s4\n",
    "\t\tself.layers = DoubleLinkedList().insert(layers)\n",
    "\t\t# функция потерь и её производная\n",
    "\t\tself.lossFunc, self.lossFuncDer = lossFunc.value\n",
    "\n",
    "\tdef fit(self, X: np.ndarray, Y: np.ndarray, n_epohs: int = 400, eps: float = 0.0001):\n",
    "\t\tself.answer = np.zeros((X.shape[0],))\n",
    "\t\tfor _ in range(n_epohs):\n",
    "\t\t\tlast_answer = np.zeros((X.shape[0],))\n",
    "\t\t\tfor i in range(X.shape[0]):\n",
    "\t\t\t\tx = X[i].reshape(1, X[i].shape[0])\n",
    "\t\t\t\n",
    "\t\t\t\t# прямое распространение\n",
    "\t\t\t\tlayer = self.layers.head\n",
    "\t\t\t\tvector = x\n",
    "\t\t\t\twhile layer != None:\n",
    "\t\t\t\t\tvector = layer.transform(vector)\n",
    "\t\t\t\t\tlayer = layer.nref\n",
    "\t\t\t\t\n",
    "\t\t\t\t#градиент ошибки\n",
    "\t\t\t\tdE_dH = self.lossFuncDer(Y[i], vector)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# обратное распространение\n",
    "\t\t\t\tlayer = self.layers.tail\n",
    "\t\t\t\twhile layer.pref != None:\n",
    "\t\t\t\t\tlayer.backprop(dE_dH)\n",
    "\t\t\t\t\tlayer = layer.pref\n",
    "\t\t\t\tlast_answer[i] = vector\n",
    "\t\t\t\n",
    "\t\t\t# точка остановки градиентного спуска\n",
    "\t\t\tif (np.fabs(self.answer - last_answer) < eps).all():\n",
    "\t\t\t\tbreak\n",
    "\t\t\tself.answer = last_answer\n",
    "\t\treturn self\n",
    "\t\n",
    "\tdef predict(self, X: np.ndarray):\n",
    "\t\tanswer = np.empty((0,self.layers.tail.n_neurons))\n",
    "\t\tfor i in range(X.shape[0]):\n",
    "\t\t\tx = X[i].reshape(1, X[i].shape[0])\n",
    "\t\t\t\n",
    "\t\t\t# прямое распространение\n",
    "\t\t\tlayer = self.layers.head\n",
    "\t\t\tvector = x\n",
    "\t\t\twhile layer != None:\n",
    "\t\t\t\tvector = layer.transform(vector)\n",
    "\t\t\t\tlayer = layer.nref\n",
    "\t\t\tanswer = np.vstack((answer,vector))\n",
    "\t\treturn answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test 1\n",
    "# model = NeuralNetwork(\n",
    "#     [Layer(2, actFunc=Func.sigmoid,lmbd=0.5), \n",
    "#      Layer(4, actFunc=Func.sigmoid,lmbd=0.5),\n",
    "#      Layer(1, actFunc=Func.linear)], \n",
    "#     lossFunc=Func.mse)\n",
    "\n",
    "# model.fit(\n",
    "# \tX=np.array([[0,0], [0,1], [1,0], [1,1]]),\n",
    "# \tY=np.array([0, 1, 1, 0]),\n",
    "# \tn_epohs=1000,\n",
    "#     eps=0.0001\n",
    "# )\n",
    "\n",
    "# model.predict(\n",
    "# \tX=np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
